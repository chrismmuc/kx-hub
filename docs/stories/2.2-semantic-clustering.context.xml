<story-context id="bmad/bmm/workflows/4-implementation/story-context/template" v="1.0">
  <metadata>
    <epicId>2</epicId>
    <storyId>2.2</storyId>
    <title>Semantic Clustering with Initial Load & Delta Processing</title>
    <status>drafted</status>
    <generatedAt>2025-11-02</generatedAt>
    <generator>BMAD Story Context Workflow</generator>
    <sourceStoryPath>docs/stories/2-2-semantic-clustering.md</sourceStoryPath>
  </metadata>

  <story>
    <asA>knowledge base user</asA>
    <iWant>my 818 knowledge chunks automatically grouped into semantic clusters based on topic similarity</iWant>
    <soThat>I can discover thematic patterns, explore related ideas, and navigate my knowledge graph by topic rather than search keywords alone</soThat>
    <tasks>
      - Task 1: Research and select clustering algorithm (AC: #2, #10)
      - Task 2: Design cluster storage schema (AC: #7, #8)
      - Task 3: Implement core clustering logic module (AC: #2, #5, #6)
      - Task 4: Implement initial load script (AC: #1, #3, #5, #10)
      - Task 5: Implement delta processing Cloud Function (AC: #4, #6, #10)
      - Task 6: Create Terraform infrastructure (AC: #4)
      - Task 7: Testing and validation (AC: #2, #5, #6, #9)
      - Task 8: Documentation and deployment (AC: #8)
    </tasks>
  </story>

  <acceptanceCriteria>
    <criterion id="1">100% coverage (Initial Load): All 818 chunks in Firestore kb_items collection assigned to at least one cluster_id</criterion>
    <criterion id="2">Cluster quality: ≥80% of cluster members are semantically related based on manual spot-check of 20 random clusters</criterion>
    <criterion id="3">Idempotency: Initial load script can be re-run to recompute clusters without data corruption</criterion>
    <criterion id="4">Delta processing integration: Cloud Function automatically processes new chunks after Knowledge Cards step in pipeline</criterion>
    <criterion id="5">Performance (Initial Load): Completes clustering of 818 chunks in ≤10 minutes</criterion>
    <criterion id="6">Performance (Delta Processing): Processes batch of new chunks in ≤5 minutes</criterion>
    <criterion id="7">Data persistence: Cluster assignments stored in kb_items.cluster_id field (array of cluster IDs)</criterion>
    <criterion id="8">Graph export: Generate graph.json in Cloud Storage with cluster relationships and metadata</criterion>
    <criterion id="9">Cost efficiency: Total cost ≤$0.10/month (reuses existing embeddings, no new AI calls)</criterion>
    <criterion id="10">Firestore batch efficiency: Use batch writes (≤500 ops/batch) for optimal performance</criterion>
  </acceptanceCriteria>

  <artifacts>
    <docs>
      <doc>
        <path>docs/PRD.md</path>
        <title>Product Requirements Document</title>
        <section>4. Data Flows - Batch Processing Pipeline</section>
        <snippet>Pipeline step 5: "Cluster & Link → Firestore links + Cloud Storage graph.json". Defines clustering as part of the daily batch pipeline flow after knowledge cards generation.</snippet>
      </doc>
      <doc>
        <path>docs/PRD.md</path>
        <title>Product Requirements Document</title>
        <section>5. Data Model (Brief)</section>
        <snippet>Firestore kb_items fields include "cluster_id[], similar_ids[], scores[]" and kb_clusters collection with "label, members[], parent_cluster?, related_clusters[]"</snippet>
      </doc>
      <doc>
        <path>docs/architecture.md</path>
        <title>Architecture Document</title>
        <section>Batch Processing Pipeline</section>
        <snippet>Pipeline diagram shows "F5[Cloud Function: Cluster & Link]" integrated into the daily workflow after embeddings and knowledge cards generation.</snippet>
      </doc>
      <doc>
        <path>docs/architecture.md</path>
        <title>Architecture Document</title>
        <section>Development Guidelines for AI Agents - Infrastructure Management Policy</section>
        <snippet>CRITICAL: All infrastructure changes MUST be managed through Terraform. Use terraform plan/apply workflow. Never use gcloud create/update/delete for resources.</snippet>
      </doc>
      <doc>
        <path>docs/architecture.md</path>
        <title>Architecture Document</title>
        <section>Technology Selection and Research</section>
        <snippet>Mandatory web research for latest stable versions, API documentation, best practices, and regional availability before implementing any feature with external interfaces or libraries.</snippet>
      </doc>
      <doc>
        <path>docs/epics.md</path>
        <title>Epics Breakdown</title>
        <section>Story 2.2: Semantic Clustering</section>
        <snippet>Two execution modes: Initial load (local script for bulk processing) and delta processing (Cloud Function for daily pipeline). Uses cosine similarity on existing 768-dim embeddings. HDBSCAN or K-Means clustering methods.</snippet>
      </doc>
      <doc>
        <path>docs/stories/2.1-knowledge-cards.md</path>
        <title>Story 2.1: Knowledge Card Generation</title>
        <section>Dev Notes - Architecture & Constraints</section>
        <snippet>Established two-mode execution pattern: Local script (python -m src.knowledge_cards.main) for initial generation + Cloud Function for pipeline integration. Batch processing with progress logging.</snippet>
      </doc>
      <doc>
        <path>docs/stories/2.1-knowledge-cards.md</path>
        <title>Story 2.1: Knowledge Card Generation</title>
        <section>Dev Agent Record - Completion Notes</section>
        <snippet>Successfully deployed Cloud Function to europe-west4. Service account pattern: Firestore read/write + relevant API permissions. Batch writes with 100 updates/batch. Environment variables: GCP_PROJECT, GCP_REGION, FIRESTORE_COLLECTION.</snippet>
      </doc>
    </docs>
    <code>
      <artifact>
        <path>src/mcp_server/firestore_client.py</path>
        <kind>service</kind>
        <symbol>get_firestore_client</symbol>
        <lines>33-47</lines>
        <reason>Reusable Firestore client initialization pattern with lazy loading and environment-based configuration</reason>
      </artifact>
      <artifact>
        <path>src/mcp_server/firestore_client.py</path>
        <kind>service</kind>
        <symbol>list_all_chunks</symbol>
        <lines>50-80</lines>
        <reason>Pattern for querying kb_items collection with proper error handling and logging. Demonstrates collection name from env var pattern.</reason>
      </artifact>
      <artifact>
        <path>src/knowledge_cards/generator.py</path>
        <kind>service</kind>
        <symbol>KnowledgeCardGenerator</symbol>
        <lines>full</lines>
        <reason>Reference implementation for batch processing with progress logging, retry logic, and Firestore batch writes. Follow similar pattern for clustering batch operations.</reason>
      </artifact>
      <artifact>
        <path>src/knowledge_cards/main.py</path>
        <kind>cli</kind>
        <symbol>main</symbol>
        <lines>full</lines>
        <reason>CLI entry point pattern for initial load scripts. Shows argument parsing, environment setup, and progress reporting structure to replicate for clustering initial load.</reason>
      </artifact>
      <artifact>
        <path>src/knowledge_cards/cloud_function.py</path>
        <kind>cloud-function</kind>
        <symbol>generate_knowledge_cards</symbol>
        <lines>full</lines>
        <reason>Cloud Function HTTP handler pattern for pipeline integration. Shows request parsing, batch processing of chunk IDs, and response format expected by Cloud Workflows.</reason>
      </artifact>
      <artifact>
        <path>terraform/knowledge_cards.tf</path>
        <kind>infrastructure</kind>
        <symbol>google_cloudfunctions2_function.knowledge_cards_function</symbol>
        <lines>59-100</lines>
        <reason>Template for Cloud Function Terraform resource. Copy this pattern for clustering function: service account, IAM bindings (Firestore + GCS), environment variables, timeout config.</reason>
      </artifact>
      <artifact>
        <path>terraform/workflows/batch-pipeline.yaml</path>
        <kind>workflow</kind>
        <symbol>call_knowledge_cards_function</symbol>
        <lines>130-165</lines>
        <reason>Cloud Workflows integration pattern. Shows HTTP POST to function URL, OIDC auth, timeout (60 min), retry logic, and error handling. Add clustering step after knowledge cards using same pattern.</reason>
      </artifact>
      <artifact>
        <path>tests/test_integration_knowledge_cards.py</path>
        <kind>test</kind>
        <symbol>test_generate_knowledge_cards_integration</symbol>
        <lines>full</lines>
        <reason>Integration test pattern for Cloud Function and batch processing. Shows mocking external dependencies, testing with small sample dataset, validating outputs.</reason>
      </artifact>
    </code>
    <dependencies>
      <python>
        <package name="google-cloud-firestore" version=">=2.16.0" reason="Firestore client for reading embeddings and writing cluster assignments" />
        <package name="google-cloud-storage" version=">=2.10.0" reason="Upload graph.json to Cloud Storage bucket" />
        <package name="scikit-learn" version=">=1.3.0" reason="HDBSCAN clustering algorithm (now integrated into sklearn), cosine distance calculation, cluster quality metrics" />
        <package name="numpy" version=">=1.24.0" reason="Array operations for embeddings and distance matrix computation" />
        <package name="functions-framework" version=">=3.0.0" reason="Cloud Functions runtime for delta processing function" />
      </python>
      <terraform>
        <module name="google_cloudfunctions2_function" reason="Deploy clustering Cloud Function (gen 2)" />
        <module name="google_service_account" reason="Create service account for clustering function" />
        <module name="google_project_iam_member" reason="Grant Firestore read/write and GCS write permissions" />
        <module name="google_storage_bucket_object" reason="Upload function source code zip" />
      </terraform>
    </dependencies>
  </artifacts>

  <constraints>
    <constraint id="1">Two execution modes required: (1) Initial load - local Python script for bulk clustering all 818 chunks with direct Firestore updates, (2) Delta processing - Cloud Function triggered by Cloud Workflows after knowledge cards step to assign new chunks to existing clusters</constraint>
    <constraint id="2">Reuse existing 768-dimensional embeddings from kb_items.embedding field - NO new embedding API calls allowed to meet cost target (AC #9)</constraint>
    <constraint id="3">Firestore batch writes MUST NOT exceed 500 operations per batch (Firestore limit) - implement batching logic with proper commit/retry handling (AC #10)</constraint>
    <constraint id="4">Clustering algorithm selection: Prefer HDBSCAN (no predefined cluster count, finds varying densities, handles noise) over K-Means. If HDBSCAN produces poor quality (<80% coherence), fallback to K-Means with sqrt(n) clusters</constraint>
    <constraint id="5">Use cosine distance metric for semantic similarity - compute distance matrix using sklearn.metrics.pairwise.cosine_distances before clustering</constraint>
    <constraint id="6">All infrastructure changes via Terraform - NEVER use gcloud create/update/delete commands (per architecture.md guidelines)</constraint>
    <constraint id="7">Follow established patterns from Story 2.1 (knowledge cards): service account with Firestore + GCS permissions, environment variables (GCP_PROJECT, GCP_REGION, FIRESTORE_COLLECTION), batch processing with progress logging</constraint>
    <constraint id="8">Initial load script must be idempotent - clear existing cluster_id arrays before recomputing to allow reruns (AC #3)</constraint>
    <constraint id="9">Delta processing function timeout: 5 minutes maximum for typical daily batches (AC #6). Use HTTP POST from Cloud Workflows with JSON payload containing chunk IDs</constraint>
    <constraint id="10">Graph export format (graph.json): Include nodes (chunks with cluster assignments), edges (similarity relationships), and cluster metadata (id, label, size) for Epic 3 consumption</constraint>
  </constraints>

  <interfaces>
    <interface>
      <name>Firestore kb_items Collection - Read</name>
      <kind>database-read</kind>
      <signature>db.collection('kb_items').stream() → List[DocumentSnapshot with {embedding: Vector(768), content: str, ...}]</signature>
      <path>src/mcp_server/firestore_client.py:list_all_chunks</path>
      <description>Query all chunks to retrieve embeddings for clustering. Each document contains 768-dim embedding vector in Vector type.</description>
    </interface>
    <interface>
      <name>Firestore kb_items Collection - Batch Write</name>
      <kind>database-write</kind>
      <signature>batch.update(doc_ref, {'cluster_id': [str]}); batch.commit() after ≤500 operations</signature>
      <path>Firestore API pattern</path>
      <description>Update cluster_id field (array of strings) for chunks. Must commit every 500 operations max to respect Firestore limits.</description>
    </interface>
    <interface>
      <name>Cloud Workflows - Clustering Function Invocation</name>
      <kind>http-trigger</kind>
      <signature>POST https://europe-west4-{project}.cloudfunctions.net/clustering-function with JSON: {chunk_ids: [str], run_id: str}</signature>
      <path>terraform/workflows/batch-pipeline.yaml:call_knowledge_cards_function</path>
      <description>Cloud Workflows calls clustering function via HTTP POST with OIDC auth. Expects response: {status: "success", clusters_assigned: int, processing_time_sec: float}</description>
    </interface>
    <interface>
      <name>HDBSCAN Clustering API</name>
      <kind>library-api</kind>
      <signature>HDBSCAN(metric='precomputed', min_cluster_size=3, min_samples=2).fit_predict(distance_matrix) → ndarray[int]</signature>
      <path>scikit-learn 1.3+ HDBSCAN</path>
      <description>Clustering algorithm using precomputed cosine distance matrix. Returns cluster labels (non-negative integers) or -1 for noise points.</description>
    </interface>
    <interface>
      <name>Cosine Distance Calculation</name>
      <kind>library-api</kind>
      <signature>cosine_distances(embeddings: ndarray[n, 768]) → ndarray[n, n]</signature>
      <path>sklearn.metrics.pairwise</path>
      <description>Compute pairwise cosine distances for all embeddings. Returns symmetric distance matrix for HDBSCAN input.</description>
    </interface>
    <interface>
      <name>Cloud Storage - Graph Export</name>
      <kind>storage-write</kind>
      <signature>bucket.blob('graphs/graph.json').upload_from_string(json.dumps(graph_data))</signature>
      <path>google.cloud.storage API</path>
      <description>Upload generated graph.json to GCS bucket for Epic 3 export workflows. JSON structure: {nodes: [], edges: [], clusters: []}</description>
    </interface>
  </interfaces>

  <tests>
    <standards>
      Follow existing test patterns from Story 2.1 (knowledge cards):
      - Unit tests with mocked external dependencies (Firestore, GCS)
      - Integration tests with small sample datasets (50-100 chunks)
      - Test framework: pytest with fixtures for test data
      - Mock Firestore using @patch('google.cloud.firestore.Client')
      - Verify outputs: cluster assignments, batch write counts, graph.json structure
      - Performance testing: measure clustering time for 818 chunks (target ≤10 min)
      - Quality validation: manual spot-check of 20 random clusters for semantic coherence
    </standards>
    <locations>
      - tests/test_clusterer.py (unit tests for clustering algorithms)
      - tests/test_integration_clustering.py (integration tests for initial load + delta processing)
      - tests/fixtures/ (test data: sample embeddings, mock Firestore documents)
    </locations>
    <ideas>
      <idea ac="2">Test HDBSCAN clustering with synthetic embeddings (10 samples, 3 known groups) - verify cluster labels separate groups correctly</idea>
      <idea ac="2">Test K-Means fallback with synthetic data - verify produces K clusters as expected</idea>
      <idea ac="3">Test idempotency: run initial load twice with same data, verify cluster assignments are deterministic (same results)</idea>
      <idea ac="5,6">Performance test: measure clustering time for 818 real chunks, assert ≤10 min for initial load, ≤5 min for 50-chunk delta batch</idea>
      <idea ac="7">Test Firestore batch write: mock client, verify batch.commit() called every 500 operations, verify cluster_id field updated correctly</idea>
      <idea ac="8">Test graph.json generation: verify JSON structure has nodes/edges/clusters, validate schema against expected format for Epic 3</idea>
      <idea ac="9">Cost validation test: verify zero Vertex AI API calls during clustering (only Firestore reads/writes + local computation)</idea>
      <idea ac="10">Test Firestore batch limit: attempt to update 600 chunks, verify splits into 2 batches (500 + 100), both committed successfully</idea>
      <idea ac="4">Integration test: mock Cloud Workflows HTTP POST to clustering function, verify processes chunk IDs and returns expected response format</idea>
    </ideas>
  </tests>
</story-context>
