# Story 3.8: Enhanced Recommendation Ranking

Status: drafted

## Story

As a knowledge base user receiving reading recommendations,
I want each request to surface fresh, diverse results with recency-aware scoring,
so that I consistently discover new content without seeing the same recommendations repeatedly, while prioritizing timely articles on evolving topics.

## Acceptance Criteria

1. **Recency-aware scoring:** Ranking algorithm incorporates publication date with configurable decay
   - Exponential decay function with configurable half-life (default: 90 days)
   - Articles older than `max_age_days` (default: 365) excluded from results
   - Recency weight configurable (default: 25% of total score)
2. **Multi-factor ranking:** Combined score from multiple weighted factors
   - `relevance_score` (50%): Semantic similarity to KB content
   - `recency_score` (25%): Exponential decay based on publication age
   - `depth_score` (15%): Gemini quality assessment (normalized 1-5 → 0-1)
   - `authority_score` (10%): Author recognition from existing KB
   - Weights configurable via Firestore `config/ranking_weights`
3. **Result diversity:** Each request surfaces different results
   - "Already shown" tracking per user with configurable TTL (default: 7 days)
   - Novelty bonus (+0.1) for never-shown recommendations
   - Diversity penalty (-0.05) for domain duplicates beyond first
   - Stochastic sampling with temperature parameter (default: 0.3)
4. **Slot-based rotation:** Recommendation slots target different content types
   - Slot 1-2: Top relevance from active clusters
   - Slot 3: Serendipity pick from related but unexplored cluster
   - Slot 4: Stale cluster refresh (clusters with oldest content)
   - Slot 5: Trending/recent from any relevant domain
5. **Query variation:** Search queries vary between requests
   - Rotate cluster focus based on session or time-based seed
   - Synonym and perspective variation in query phrasing
   - "Beyond what you know" queries using knowledge card takeaways
6. **Exclude previously shown:** URLs shown in recent sessions filtered out
   - Tavily `exclude_urls` parameter for search exclusion
   - Post-filter for any URLs in `shown_recommendations` collection
7. **Configuration management:** All parameters stored in Firestore
   - `config/ranking_weights`: Factor weights
   - `config/ranking_settings`: Recency half-life, TTL, temperature
   - Editable via MCP tool `update_ranking_config()`
8. **Transparent scoring:** Response includes score breakdown for each recommendation
   - Individual factor scores visible
   - Combined score calculation shown
   - Slot assignment explained

## Tasks / Subtasks

- [ ] Task 1: Implement recency scoring function (AC: #1)
  - [ ] Create `calculate_recency_score(published_date, half_life_days)` in `recommendation_filter.py`
  - [ ] Implement exponential decay: `exp(-ln(2) * age_days / half_life_days)`
  - [ ] Add `max_age_days` cutoff filter
  - [ ] Unit tests for various age scenarios (today, 30d, 90d, 180d, 365d)
  - [ ] Handle missing publication dates gracefully (assign neutral score 0.5)

- [ ] Task 2: Implement multi-factor ranking (AC: #2, #8)
  - [ ] Create `calculate_combined_score(result, weights)` function
  - [ ] Normalize all factor scores to 0-1 range
  - [ ] Implement weighted sum with configurable weights
  - [ ] Add score breakdown to recommendation response
  - [ ] Unit tests for score combination

- [ ] Task 3: Implement "shown recommendations" tracking (AC: #3, #6)
  - [ ] Create Firestore collection `shown_recommendations/{user_id}/items`
  - [ ] Document structure: `{url, shown_at, expires_at}`
  - [ ] Implement `record_shown(user_id, urls)` in firestore helpers
  - [ ] Implement `get_shown_urls(user_id, ttl_days)` query
  - [ ] Add TTL-based auto-cleanup (Firestore TTL policy or Cloud Function)
  - [ ] Filter shown URLs from results in recommendation engine

- [ ] Task 4: Implement stochastic sampling (AC: #3)
  - [ ] Create `diversified_sample(results, n, temperature)` function
  - [ ] Implement softmax over scores with temperature parameter
  - [ ] Temperature 0 = deterministic (top-N), temperature 1 = uniform random
  - [ ] Default temperature: 0.3 (mild randomization)
  - [ ] Unit tests for sampling distribution

- [ ] Task 5: Implement slot-based rotation (AC: #4)
  - [ ] Define slot strategy enum: RELEVANCE, SERENDIPITY, STALE_REFRESH, TRENDING
  - [ ] Implement `assign_slot(recommendation, slot_type)` logic
  - [ ] Create `get_serendipity_cluster()` - find related but unread cluster
  - [ ] Create `get_stale_clusters(threshold_days)` - clusters needing refresh
  - [ ] Implement slot filling algorithm in main recommendation function

- [ ] Task 6: Implement query variation (AC: #5)
  - [ ] Create `generate_varied_queries(themes, session_seed)` function
  - [ ] Implement cluster rotation based on time/session
  - [ ] Add synonym expansion for key terms
  - [ ] Create "beyond" query templates using takeaways
  - [ ] Unit tests for query variety

- [ ] Task 7: Implement configuration management (AC: #7)
  - [ ] Create Firestore document `config/ranking_weights`
  - [ ] Create Firestore document `config/ranking_settings`
  - [ ] Implement `get_ranking_config()` in firestore_client.py
  - [ ] Implement `update_ranking_config()` MCP tool
  - [ ] Validate weight sum equals 1.0
  - [ ] Register tool in main.py

- [ ] Task 8: Integrate with recommendation engine (AC: #1-8)
  - [ ] Modify `get_reading_recommendations()` to use new ranking
  - [ ] Add `exclude_urls` parameter to Tavily searches
  - [ ] Record shown URLs after successful response
  - [ ] Include score breakdown in response format
  - [ ] Add slot assignment to each recommendation

- [ ] Task 9: Testing and validation (AC: #1-8)
  - [ ] Unit tests for all scoring functions
  - [ ] Integration test: Multiple requests return different results
  - [ ] Integration test: Recency scoring affects ranking
  - [ ] Manual validation: Request recommendations 3x, verify variety
  - [ ] Performance test: Verify <60s response time maintained

## Dev Notes

### Architecture

**Recency Scoring Formula:**
```python
import math
from datetime import datetime

def calculate_recency_score(
    published_date: datetime,
    half_life_days: int = 90,
    max_age_days: int = 365
) -> float:
    """
    Exponential decay based on article age.

    Returns:
    - 1.0 for articles published today
    - 0.5 for articles at half_life_days age
    - 0.25 for articles at 2x half_life_days
    - 0.0 for articles older than max_age_days (filtered out)

    Examples (half_life=90):
    - Today: 1.0
    - 30 days: 0.79
    - 90 days: 0.50
    - 180 days: 0.25
    - 365 days: 0.06
    """
    age_days = (datetime.now() - published_date).days

    if age_days > max_age_days:
        return 0.0  # Filter out

    if age_days <= 0:
        return 1.0

    decay_rate = math.log(2) / half_life_days
    return math.exp(-decay_rate * age_days)
```

**Multi-Factor Ranking:**
```python
def calculate_combined_score(
    result: dict,
    weights: dict
) -> dict:
    """
    Combine multiple factors into final ranking score.

    Default weights:
    - relevance: 0.50 (semantic similarity)
    - recency: 0.25 (publication freshness)
    - depth: 0.15 (content quality)
    - authority: 0.10 (author recognition)
    """
    scores = {
        'relevance': result.get('similarity_score', 0.5),
        'recency': calculate_recency_score(result.get('published_date')),
        'depth': result.get('depth_score', 3) / 5.0,  # Normalize 1-5 → 0-1
        'authority': result.get('author_authority', 0.5),
    }

    combined = sum(weights[k] * scores[k] for k in weights)

    return {
        'combined_score': round(combined, 3),
        'score_breakdown': {k: round(v, 3) for k, v in scores.items()},
        'weights_used': weights
    }
```

**Stochastic Sampling:**
```python
import numpy as np

def diversified_sample(
    results: list,
    n: int,
    temperature: float = 0.3
) -> list:
    """
    Sample results with controlled randomness.

    temperature=0: Deterministic (always top-N)
    temperature=0.3: Mild randomization (default)
    temperature=1.0: High randomization
    """
    if temperature == 0 or len(results) <= n:
        return results[:n]

    scores = np.array([r['combined_score'] for r in results])

    # Softmax with temperature
    exp_scores = np.exp(scores / temperature)
    probabilities = exp_scores / exp_scores.sum()

    # Sample without replacement
    indices = np.random.choice(
        len(results),
        size=min(n, len(results)),
        replace=False,
        p=probabilities
    )

    return [results[i] for i in sorted(indices)]
```

**Slot-Based Rotation Strategy:**
```
┌─────────────────────────────────────────────────────────┐
│                 5 Recommendation Slots                  │
├─────────────────────────────────────────────────────────┤
│                                                         │
│  Slot 1-2: RELEVANCE                                   │
│  ├── Highest combined_score from active clusters       │
│  └── Core recommendations matching user interests      │
│                                                         │
│  Slot 3: SERENDIPITY                                   │
│  ├── Pick from cluster related to but NOT in top-5    │
│  ├── Use get_related_clusters() (Story 3.4)           │
│  └── Enables discovery beyond filter bubble            │
│                                                         │
│  Slot 4: STALE_REFRESH                                 │
│  ├── Cluster with oldest average content age           │
│  ├── Prioritize clusters user cares about but stale   │
│  └── Keeps knowledge current in important areas        │
│                                                         │
│  Slot 5: TRENDING                                      │
│  ├── Highest recency_score among relevant results     │
│  ├── May sacrifice some relevance for freshness       │
│  └── Captures breaking developments                    │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

**Shown Recommendations Tracking:**
```
Firestore: shown_recommendations/{user_id}/items/{doc_id}

Document structure:
{
  "url": "https://example.com/article",
  "url_hash": "sha256_first_12_chars",  // For efficient querying
  "shown_at": Timestamp,
  "expires_at": Timestamp,  // shown_at + TTL
  "slot_type": "RELEVANCE",
  "combined_score": 0.823,
  "session_id": "optional_session_reference"
}

TTL Policy: Firestore auto-deletes documents past expires_at
```

**Configuration Documents:**

`config/ranking_weights`:
```json
{
  "relevance": 0.50,
  "recency": 0.25,
  "depth": 0.15,
  "authority": 0.10,
  "last_updated": "2025-12-11",
  "updated_by": "initial_setup"
}
```

`config/ranking_settings`:
```json
{
  "recency": {
    "half_life_days": 90,
    "max_age_days": 365,
    "tavily_days_filter": 180
  },
  "diversity": {
    "shown_ttl_days": 7,
    "novelty_bonus": 0.10,
    "domain_duplicate_penalty": 0.05,
    "max_per_domain": 2,
    "stochastic_temperature": 0.3
  },
  "slots": {
    "relevance_count": 2,
    "serendipity_count": 1,
    "stale_refresh_count": 1,
    "trending_count": 1
  },
  "last_updated": "2025-12-11"
}
```

### Enhanced Response Format

```json
{
  "generated_at": "2025-12-11T14:30:00Z",
  "processing_time_seconds": 38,
  "scope": "both",
  "config_used": {
    "weights": {"relevance": 0.50, "recency": 0.25, "depth": 0.15, "authority": 0.10},
    "half_life_days": 90,
    "temperature": 0.3
  },
  "diversity_stats": {
    "excluded_shown_count": 3,
    "novelty_bonuses_applied": 4,
    "domain_penalties_applied": 1
  },
  "recommendations": [
    {
      "title": "The Future of Platform Engineering",
      "url": "https://martinfowler.com/articles/...",
      "author": "Martin Fowler",
      "domain": "martinfowler.com",
      "published_date": "2025-12-01",
      "snippet": "...",
      "slot": "RELEVANCE",
      "slot_reason": "Top combined score from Platform Engineering cluster",
      "scoring": {
        "combined_score": 0.847,
        "breakdown": {
          "relevance": 0.92,
          "recency": 0.89,
          "depth": 0.80,
          "authority": 0.75
        },
        "adjustments": {
          "novelty_bonus": 0.10,
          "domain_penalty": 0.00
        },
        "final_score": 0.947
      },
      "related_to": {
        "cluster_id": "cluster-28",
        "cluster_name": "Platform Engineering and Developer Experience"
      },
      "why_recommended": "Expands on your recent reading about internal platforms..."
    },
    {
      "title": "Emerging Patterns in AI Agents",
      "url": "https://anthropic.com/research/...",
      "slot": "SERENDIPITY",
      "slot_reason": "From AI Agents cluster (related to your MCP interest)",
      "scoring": {
        "combined_score": 0.723,
        "breakdown": { "relevance": 0.68, "recency": 0.95, "depth": 0.70, "authority": 0.60 }
      }
    }
  ]
}
```

### Trade-off Considerations

| Parameter | Lower Value | Higher Value |
|-----------|-------------|--------------|
| `half_life_days` | Aggressively favors recent content | Classic/evergreen content included |
| `temperature` | Deterministic, predictable | High variety, less optimal |
| `shown_ttl_days` | Quick recommendation recycling | Longer freshness guarantee |
| `relevance_weight` | More serendipity | More focused results |
| `recency_weight` | Timeless content | Breaking/trending content |

**Recommended Starting Configuration:**
- `half_life_days: 90` - Balance between fresh and classic
- `temperature: 0.3` - Mild randomization for variety
- `shown_ttl_days: 7` - Weekly refresh cycle
- Weights: 50/25/15/10 split prioritizes relevance

### Project Structure Notes

**Files to Modify:**
- `src/mcp_server/recommendation_filter.py` - Add recency scoring, combined ranking
- `src/mcp_server/recommendation_queries.py` - Add query variation logic
- `src/mcp_server/tools.py` - Add `update_ranking_config()` tool
- `src/mcp_server/main.py` - Register new tool
- `src/mcp_server/firestore_client.py` - Add shown_recommendations CRUD

**New Functions:**
- `calculate_recency_score()`
- `calculate_combined_score()`
- `diversified_sample()`
- `record_shown_recommendations()`
- `get_shown_urls()`
- `get_serendipity_cluster()`
- `get_stale_clusters()`

### Dependencies

- **Story 3.5** (Reading Recommendations): Base recommendation engine
- **Story 3.4** (Cluster Relationships): `get_related_clusters()` for serendipity slot
- **NumPy**: For stochastic sampling (already in dependencies)

### Cost Analysis

| Component | Monthly Cost |
|-----------|-------------|
| Firestore shown_recommendations | ~$0.01 (5 docs/week × 4 weeks) |
| Additional queries | ~$0.01 |
| **Total Additional** | **~$0.02/month** |

### References

- [Source: docs/stories/3.5-reading-recommendations.md] - Base recommendation engine
- [Source: docs/stories/3.4-cluster-relationship-discovery.md] - Cluster relationships
- [Source: src/mcp_server/tools.py] - Existing tool patterns

## Dev Agent Record

### Context Reference

<!-- Path(s) to story context XML will be added here by context workflow -->

### Agent Model Used

Claude Opus 4.5

### Debug Log References

### Completion Notes List

### File List
