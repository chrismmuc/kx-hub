---
epicNum: 1
storyNum: 4
title: "Pipeline Delta Manifests & Resume Controls"
status: "Ready for Review"
---

# Story: Pipeline Delta Manifests & Resume Controls

As a **system operator**, I want **each pipeline run to process only new or changed items and resume safely after failures**, so that **daily automation stays fast, avoids duplicate embeddings, and can recover without manual cleanup**.

## Acceptance Criteria

1. **Run Manifest**: The ingest function must emit a manifest (`gs://{project}-pipeline/manifests/{run_id}.json`) that lists each processed item ID, raw object URI, `updated_at`, and a `raw_checksum` computed as the SHA-256 hash of the raw JSON payload. The completion Pub/Sub message must include the `run_id`.
2. **Workflow Propagation**: `batch-pipeline.yaml` must pass the `run_id` to the normalize and embed steps (HTTP body payload) and guard against missing manifests.
3. **Normalize Delta Processing**: The normalize function must read the manifest and skip items already marked `normalize_status == "complete"` in Firestore unless the raw checksum changed. For new or changed items it must write markdown, update `pipeline_items` with `normalize_status`, `content_hash`, and `manifest_run_id`.
4. **Embed Resume Logic**: The embed function must query `pipeline_items` for entries where `embedding_status != "complete"` or `content_hash` changed since the last embedding, mark them `processing`, and upon success update `embedding_status`, `last_embedded_at`, and clear `last_error`. Entries that remain `processing` longer than 15 minutes must be treated as retries by resetting to `pending` (incrementing `retry_count`). Failures must set `embedding_status = "failed"` with populated `last_error`.
5. **Idempotent Upserts**: Vector Search upserts and Firestore writes must include the manifest `run_id` so replays of the same run do not create duplicates. Re-running the embed function for the same `run_id` when all items are `complete` must result in zero additional upserts and no Firestore field changes.
6. **Operational Visibility**: Add Cloud Logging entries summarizing counts of `pending`, `processing`, `complete`, `failed`, and surface totals in the function responses. Provide `verify-deployment.sh` commands to inspect manifest objects and `pipeline_items` state.
7. **First Production Load**: Execute the full pipeline end-to-end with the new manifest logic (ingest → normalize → embed) and verify 271 embeddings + matching Firestore docs are created exactly once; run a Vector Search sanity query to confirm results.
8. **Manifest Replay Test**: Replay the exact manifest (`run_id`) after the pipeline reports success and demonstrate that the normalize and embed stages skip work (zero new markdown writes, zero Vector Search upserts, unchanged Firestore documents).
9. **Stop-and-Resume Test**: Document and execute a manual validation where the embed function is interrupted (simulate by forcing a failure), confirm Firestore shows `failed` items, then rerun the pipeline to verify only failed items are retried and no duplicates appear in Vector Search or Firestore while aged `processing` entries are recovered per the 15-minute timeout.

## Dev Notes

- **Inputs**: `run_id` string, manifest JSON (`items: [{id, raw_uri, updated_at, raw_checksum}]`), Firestore `pipeline_items`.
- **Manifest Schema Example:**
  ```json
  {
    "run_id": "2025-10-20T02-00-00Z-3f4c8d2e",
    "generated_at": "2025-10-20T02:00:15Z",
    "items": [
      {
        "id": "51822710",
        "raw_uri": "gs://kx-hub-raw-json/readwise-book-51822710.json",
        "updated_at": "2025-10-18T20:00:00Z",
        "raw_checksum": "sha256:9e86d4f5c2c4f1a9d92f0b1c473a8d6b4f7c1a0e52e8359f2f1e5b0b7c1b8d3f"
      }
    ]
  }
  ```
- **Outputs**:
  - Updated `pipeline_items` documents with normalized and embedded statuses.
  - Idempotent upserts to Vertex AI Vector Search (unchanged IDs, no duplicates).
  - Enriched `kb_items` documents with `content_hash`, `embedding_status`, `last_embedded_at`, `last_error`.
- **Failure Recovery**:
  - Normalize errors → set `normalize_status="failed"` and keep item in manifest for manual retry.
  - Embed errors → set `embedding_status="failed"`; reruns must pick them up automatically.
  - Entries stuck in `processing` beyond 15 minutes → transition back to `pending`, increment `retry_count`, and log remediation.
- **Security**:
  - Manifests stored in private GCS bucket (`{project}-pipeline`) with least-privilege IAM.
  - `pipeline_items` writes restricted to workflow + pipeline service accounts.
- **Performance**:
  - Expected delta size: 0-20 items per day; manifest ensures we avoid reprocessing baseline 271 items.
  - Ensure Firestore queries for `embedding_status` are indexed (composite index instructions if necessary).

## Tasks / Subtasks

1. **Infrastructure (Terraform)**  
   - [x] Create GCS bucket `${var.project_id}-pipeline` with lifecycle rules for manifests.  
   - [x] Grant ingest, normalize, and embed service accounts scoped access (write/read).  
   - [x] Add Firestore composite index for `pipeline_items` (`embedding_status`, `content_hash`).  
   - [x] Extend Cloud Workflow secrets/vars to pass `run_id`.

2. **Ingest Function Updates (`src/ingest/main.py`)**  
   - [x] Generate deterministic `run_id` (timestamp + UUID).  
   - [x] Build manifest payload (item_id, raw_uri, updated_at, checksum).  
   - [x] Upload manifest JSON to GCS and publish Pub/Sub message with `run_id`.  
   - [x] Unit tests for manifest generation & Pub/Sub message.

3. **Normalize Function Updates (`src/normalize`)**  
   - [x] Accept `run_id` in request body.  
   - [x] Fetch manifest, iterate items, skip if Firestore shows matching `content_hash`.  
   - [x] Update/create `pipeline_items` documents with `normalize_status`, `content_hash`, `manifest_run_id`.  
   - [x] Log skipped vs processed counts.  
   - [x] Unit tests covering skip, dirty item re-process, and Firestore state updates.

4. **Embed Function Updates (`src/embed/main.py`)**  
   - [x] Accept `run_id`, load manifest, query `pipeline_items` for dirty/failed entries.  
   - [x] Mark entries `processing`, ensure entries older than 15 minutes automatically reset to `pending` with incremented `retry_count`.  
   - [x] On success set `embedding_status="complete"`, update `kb_items` with `content_hash`, `embedding_status`, `last_embedded_at`, `last_error=None`.  
   - [x] On failure set `embedding_status="failed"` with `last_error`.  
   - [x] Skip Vector Search upsert when content hash unchanged and log the skip reason.  
   - [x] Unit tests for resume behavior, duplicate avoidance, timeout reset, and error paths.

5. **Workflow Update (`terraform/workflows/batch-pipeline.yaml`)**  
   - [x] Parse Pub/Sub payload to extract `run_id`.  
   - [x] Pass `run_id` in normalize and embed HTTP requests.  
   - [x] Fail early with log if manifest missing; do not proceed to embed.

6. **Validation & Ops**  
   - [x] Update `verify-deployment.sh` with manifest + pipeline status commands.  
   - [x] Document stop/resume test steps in `DEPLOYMENT_CHECKLIST.md`.  
   - [ ] Run end-to-end load: trigger ingest, allow normalize + embed to finish, verify 271 embeddings, 271 Firestore docs, and run Vector Search sanity query.  
   - [ ] Replay the successful manifest (`run_id`) and confirm normalize/embed report zero processed items and no new Vector Search upserts.  
 - [ ] Run manual stop/resume drill: trigger ingest, intentionally abort embed, rerun, verify failed items recover without duplicates and `processing` entries older than 15 minutes are reset automatically.

---

**Dependencies:** Stories 1.1–1.3 must remain functional; this story precedes Story 1.5 (Cluster & Link).

## Dev Agent Record

- **Agent Model Used:** gpt-5-codex
- **Implementation Date:** 2025-10-20
- **Summary:**
  - Added Terraform resources for pipeline manifests/IAM/indexing and propagated `run_id` through Cloud Workflow invocations.
  - Emitted manifest + Pub/Sub payload from ingest, updated normalize to delta-process into `pipeline_items`, and reworked embed with stale retry handling + idempotent Vector Search writes.
  - Expanded unit coverage (ingest manifest, normalize skip/resume, embed replay) and updated deployment docs/scripts for manifest + pipeline visibility.
- **Tests:** `python3 -m unittest discover -s tests -p "test_*.py" -v`
- **File List:** `terraform/main.tf`, `terraform/workflows/batch-pipeline.yaml`, `src/ingest/main.py`, `src/normalize/main.py`, `src/embed/main.py`, `tests/test_ingest.py`, `tests/test_normalize.py`, `tests/test_embed.py`, `verify-deployment.sh`, `DEPLOYMENT_CHECKLIST.md`, `docs/prd/3-architectural-guidelines.md`, `docs/prd/4-data-flows.md`, `docs/prd/5-data-model-brief.md`, `docs/stories/1.3.story.md`.
- **Outstanding Follow-Ups:** First production load, manifest replay validation, and the stop/resume drill remain pending real-environment execution.

## QA Results

### Review Date: 2025-10-20

### Reviewed By: Quinn (Test Architect)

### Code Quality & Requirements Assessment
- Story intent is strong, but manifest schema lacks precise definition (e.g., checksum algorithm, sample JSON) which risks divergent implementations.
- Processing-timeout behavior for `pipeline_items` is mentioned, yet acceptance criteria do not specify thresholds or cleanup protocol, leaving restart semantics ambiguous.

### Requirements Traceability
- AC1–AC5 map cleanly to planned code updates, but AC5’s idempotency requirement needs explicit validation steps (e.g., rerunning the same `run_id`).
- AC7/AC8 cover end-to-end validation; ensure they incorporate the idempotency rerun.

### Test Coverage Review
- Unit tests listed for ingest/normalize/embed are appropriate; add coverage for: duplicate manifest replay, stale `processing` records auto-retry, and vector index no-op verification.
- Recommend integration test script that replays a saved manifest to assert zero additional upserts.

### NFR & Operational Observations
- Reliability: **CONCERNS** – restart handling needs concrete timeout + remediation guidance.
- Performance, Security, Maintainability: PASS given current scope.

### Issues & Recommendations
1. **Manifest Spec Ambiguity** (severity: medium, owner: `sm`/`dev`)  
   - Define checksum algorithm (e.g., SHA-256 of raw payload) and provide manifest JSON example to avoid cross-service drift.
2. **Resume Timeout Clarity** (severity: medium, owner: `dev`)  
   - Document required timeout window + retry policy for `processing` states, and add acceptance validation for cleaning up orphaned records.

### Recommended Next Status
- Keep story in **Draft** until the above issues are resolved and acceptance/tests updated.

### Review Date: 2025-10-20 (Follow-up)

### Reviewed By: Quinn (Test Architect)

### Code Quality & Requirements Assessment
- Manifest checksum now explicitly defined as SHA-256 with concrete JSON example; schema ambiguity resolved.
- Resume logic specifies 15-minute timeout with retry/reset behaviour and logging; acceptance criteria/test tasks updated accordingly.

### Requirements Traceability
- AC1–AC9 now each have explicit validation paths; AC8 ensures manifest replay yields no work, satisfying idempotency coverage.

### Test Coverage Review
- Added expectations for timeout reset/unit tests and manifest replay; coverage plan is complete for risk areas.

### NFR & Operational Observations
- Reliability: **PASS** – timeout remediation + replay validation close previous gaps.
- Performance, Security, Maintainability: PASS (unchanged).

### Issues & Recommendations
- No open issues.

### Recommended Next Status
- Story ready to promote to **Ready for Implementation** once team scheduling permits.

### Gate Status

Gate: PASS → docs/qa/gates/1.4-pipeline-delta-manifests-resume-controls.yml
